{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc3d965-631b-4aef-8709-0eca6fdff46d",
   "metadata": {},
   "source": [
    "# Appendix A code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "779a8344-8982-4eb6-8b15-8301e74ba4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95604297-6e21-458b-a7ed-83f84ebe2cf4",
   "metadata": {},
   "source": [
    "## CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e60544-e886-4339-bf1e-13f922c51717",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40458100-4dda-45fe-8c54-9368af3b5d13",
   "metadata": {},
   "source": [
    "Listing A.4 A multilayer perceptron with two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab02983-5dc6-422d-86ee-d8934089c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            # 1st hidden layer\n",
    "            torch.nn.Linear(num_inputs,30),\n",
    "            torch.nn.ReLU(),\n",
    "            # 2nd hidden layer\n",
    "            torch.nn.Linear(30,20),\n",
    "            torch.nn.ReLU(),\n",
    "            # output layer\n",
    "            torch.nn.Linear(20,num_outputs)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        logits = self.layers(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c764a7c-eb9e-4341-84e6-d87ff67ecb91",
   "metadata": {},
   "source": [
    "init a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9786136-676f-4924-a3e2-e645c38d6a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(50,3)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4a0ab2-cc97-4a63-b8c8-3547ecee1924",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8693f9-eac1-4eb6-8c44-3e8a36f823cd",
   "metadata": {},
   "source": [
    "Listing A.5 Creating a toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec5548f2-a962-4565-8c7f-547fbff6c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor([\n",
    "    [-1.2,3.1],\n",
    "    [-0.9,2.9],\n",
    "    [-0.5,2.6],\n",
    "    [2.3,-1.1],\n",
    "    [2.7,-1.5]\n",
    "])\n",
    "y_train = torch.tensor([0,0,0,1,1])\n",
    "\n",
    "x_test = torch.tensor([\n",
    "    [-0.8, 2.8],\n",
    "    [2.6, -1.6]\n",
    "])\n",
    "y_test = torch.tensor([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb2742b-a9c6-4a44-bab6-a94818d90621",
   "metadata": {},
   "source": [
    "Listing A.6 Defining a custom Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b9096f0-fe91-4175-bebb-2247be3b6d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.features = X\n",
    "        self.labels = Y\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        x = self.features[index]\n",
    "        y = self.labels[index]\n",
    "        return x, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae934f80-8d10-471b-bb33-5b26cd8d0a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ToyDataset(x_train, y_train)\n",
    "test_ds = ToyDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b9066c-37c4-4723-b520-9b7297e4d9fd",
   "metadata": {},
   "source": [
    "Listing A.7 Init data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "725db1fb-192c-4669-804a-792ac9daa6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset = train_ds,\n",
    "    batch_size = 2,\n",
    "    shuffle = True,\n",
    "    num_workers = 0,\n",
    "    drop_last = True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset = test_ds,\n",
    "    batch_size = 2,\n",
    "    shuffle = False,\n",
    "    num_workers = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e128a26-2a1a-4a92-b476-234e0e1e23bb",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dbf533-95c8-4970-9802-7fd7eaf1df65",
   "metadata": {},
   "source": [
    "Listing A.9 A toy training cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5c3a64de-0680-4184-990f-206f6855f396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/004 | Batch 000/002 | Train Loss: 1.12\n",
      "Epoch: 001/004 | Batch 001/002 | Train Loss: 0.72\n",
      "Epoch: 002/004 | Batch 000/002 | Train Loss: 0.18\n",
      "Epoch: 002/004 | Batch 001/002 | Train Loss: 0.08\n",
      "Epoch: 003/004 | Batch 000/002 | Train Loss: 0.01\n",
      "Epoch: 003/004 | Batch 001/002 | Train Loss: 0.01\n",
      "Epoch: 004/004 | Batch 000/002 | Train Loss: 0.01\n",
      "Epoch: 004/004 | Batch 001/002 | Train Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "# construct the model and the optimizer\n",
    "model = NeuralNetwork(num_inputs = 2, num_outputs = 2)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.5)\n",
    "\n",
    "# train\n",
    "num_epoch = 4\n",
    "for epoch in range(num_epoch):\n",
    "    # set model in training mode\n",
    "    model.train()\n",
    "\n",
    "    # batches\n",
    "    for batch_index, (features, labels) in enumerate(train_loader):\n",
    "        logits = model(features)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        # optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        #logging\n",
    "        print(f\"Epoch: {epoch+1:03d}/{num_epoch:03d}\"\n",
    "        f\" | Batch {batch_index:03d}/{len(train_loader):03d}\"\n",
    "        f\" | Train Loss: {loss:.2f}\")\n",
    "\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448e1073-3907-4467-aca2-7a6a24fa93a7",
   "metadata": {},
   "source": [
    "model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9793e657-1983-4f20-9fc1-f5da59f44111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True])\n",
      "tensor(10)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "torch.argmax(model(x_train),dim=1)\n",
    "torch.argmax(model(x_train),dim=1)==y_train\n",
    "compare = torch.argmax(model(x_train),dim=1)==y_train\n",
    "print(compare)\n",
    "print(5+torch.sum(compare))\n",
    "print(len(compare))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d07fb3-215c-4c2f-a132-a57ba7a91c52",
   "metadata": {},
   "source": [
    "### Validating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922fa5d9-b500-42a8-86d6-7078f28d85fe",
   "metadata": {},
   "source": [
    "Listing A.10 Compute prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6e34ef6c-9d95-49c8-a2ab-787429ff8f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model,dataloader):\n",
    "    model = model.eval()\n",
    "    correct = 0.0\n",
    "    total_example = 0.0\n",
    "\n",
    "    for batch_index, (features, labels) in enumerate(dataloader):\n",
    "        # forward\n",
    "        with torch.no_grad():\n",
    "            logits = model(features)\n",
    "\n",
    "        # validate\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        '''print(f\"predictions: {predictions}\"\n",
    "            f\" | labels: {labels}\")'''\n",
    "        compare = predictions == labels\n",
    "        correct +=torch.sum(compare)\n",
    "        total_example += len(compare)\n",
    "\n",
    "    return (correct/total_example).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8c3a4dec-d1e5-4106-aacd-2b0e4ea7e1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(compute_accuracy(model, train_loader))\n",
    "print(compute_accuracy(model, test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8434c5a2-e0bd-4cd0-8ec8-bd50b657b924",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3005a5a1-55a4-4035-acee-b1b589252f62",
   "metadata": {},
   "source": [
    "### GPU info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "22875702-4501-493c-b316-fb0e60c1bb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: True\n",
      "#GPU = 1\n"
     ]
    }
   ],
   "source": [
    "# GPU available\n",
    "print(f\"GPU is available: {torch.cuda.is_available()}\")\n",
    "# GPU ranks\n",
    "print(f\"#GPU = {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "20d5dcf5-0781-4b9c-992c-aa7dd1ce6a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs available: 1\n",
      "\n",
      "--- GPU 0 ---\n",
      "Name: NVIDIA RTX A400\n",
      "Total VRAM: 4.00 GB\n",
      "Compute Capability: 8.6\n",
      "Multi-Processor Count: 6\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"GPUs available: {gpu_count}\\n\")\n",
    "\n",
    "    for i in range(gpu_count):\n",
    "        name = torch.cuda.get_device_name(i)\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "\n",
    "        print(f\"--- GPU {i} ---\")\n",
    "        print(f\"Name: {name}\")\n",
    "        print(f\"Total VRAM: {props.total_memory / (1024**3):.2f} GB\")\n",
    "        print(f\"Compute Capability: {props.major}.{props.minor}\")\n",
    "        print(f\"Multi-Processor Count: {props.multi_processor_count}\")\n",
    "else:\n",
    "    print(\"No CUDA-compatible GPU detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbaa681-247d-4b89-8443-b93692b73989",
   "metadata": {},
   "source": [
    "## Generalized training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2cf6801f-2711-42b0-b7f2-3d50be910353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/004 | Batch 000/002 | Train Loss: 1.12\n",
      "Epoch: 001/004 | Batch 001/002 | Train Loss: 0.72\n",
      "Epoch: 002/004 | Batch 000/002 | Train Loss: 0.18\n",
      "Epoch: 002/004 | Batch 001/002 | Train Loss: 0.08\n",
      "Epoch: 003/004 | Batch 000/002 | Train Loss: 0.01\n",
      "Epoch: 003/004 | Batch 001/002 | Train Loss: 0.01\n",
      "Epoch: 004/004 | Batch 000/002 | Train Loss: 0.01\n",
      "Epoch: 004/004 | Batch 001/002 | Train Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# construct the model and the optimizer\n",
    "model = NeuralNetwork(num_inputs = 2, num_outputs = 2)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.5)\n",
    "\n",
    "# send modelto device\n",
    "model.to(device)\n",
    "\n",
    "# train\n",
    "num_epoch = 4\n",
    "for epoch in range(num_epoch):\n",
    "    # set model in training mode\n",
    "    model.train()\n",
    "\n",
    "    # batches\n",
    "    for batch_index, (features, labels) in enumerate(train_loader):\n",
    "        # send dataset to device\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        \n",
    "        logits = model(features)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        # optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        #logging\n",
    "        print(f\"Epoch: {epoch+1:03d}/{num_epoch:03d}\"\n",
    "        f\" | Batch {batch_index:03d}/{len(train_loader):03d}\"\n",
    "        f\" | Train Loss: {loss:.2f}\")\n",
    "\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacb9809-3fc2-4ed6-9bf1-6101e03da312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
